{"Mathematics/Mathematical-Methods-in-Physics/Infinite-Series":{"title":"Infinite Series","links":[],"tags":["mathematics","preliminaries"],"content":"Infinite series are the mostly widely used tools in physics, and it is crucial to know how to use them properly. The topics discussed here serve as preludes to further analysis, or numerical methods.\nNote that this will not be a rigorous exposition on infinite series - that belongs to the realm of mathematical analysis. We will be satisfied by just knowing the tricks of the trade.\nFundamental definitions\nUsually, we go about defining an infinite series using something called partial sums.\n\n\n                  \n                  Partial Sums \n                  \n                \n\nLet us have a sequence \\{a_{n}\\}_{n=1}^{\\infty}. Then, we define the ith partial sum of this sequence as:\ns_{i} = \\sum_{n=1}^{i} a_{n}\nThis is a finite sum, and thus offers no problem. A convenient starting point.\n\n\nNow, we define,\n\\lim_{ n \\to \\infty } s_{n} = \\sum_{n=1}^{\\infty}a_{n}\nas the infinite series.\nWe can now comment on the “convergence” of such a sum.\n\n\n                  \n                  What is the criteria for convergence of an infinite series? \n                  \n                \n\n\nFirst Principle Criteria: If the limit \\lim_{ n \\to \\infty } s_{n} exists, and is equal to some S, then we say that the infinite series converges, and is equal to S. This is denoted by \\sum_{n=1}^{\\infty} a_{n} = S. Note that is a definition of the value of the series - one that is consistent with our ideas of addition.\nCauchy Criteria: If \\forall \\epsilon &gt; 0  \\exists N_{\\epsilon} \\in \\mathbb{N} such that |s_{i} - s_{j}| &lt; \\epsilon \\forall i, j &gt; N_{\\epsilon}, then we say that the series is Cauchy, and that it converges. This essentially means that the partial sums are “bunching together” for sufficiently large values of n.\n\n\n\nThere are mainly three types of series:\n\nConvergent Series: Satisfying the definition of convergence defined above.\nDivergent Series: Series that do not converge.\nOscillatory Series: Series that do not converge to a value, but oscillate between two bounds in the sufficiently large n limit.\n\n\n\n                  \n                  Example: Oscillatory Series \n                  \n                \n\nThe series defined by,\n\\sum_{n=1}^{\\infty} u_{n} = 1 + (-1) + 1 + \\dots + (-1)^n + \\dots\noscillates between 1 and 0 in the limit n \\to \\infty.\n\n\nIt should be noted that often Oscillatory Series are subsumed under Divergent Series, i.e. all Oscillatory series are divergent series but not all divergent series are oscillatory series.\nNote: The requirement that \\lim_{ n \\to \\infty } a_{n} = 0 for \\sum_{n=0}^{\\infty} a_{n} to converge is a necessary requirement, but not a sufficient one. This means that all convergent series satisfy this necessary condition, but not all series satisfying the necessary condition are convergent!\n\n\n                  \n                  Geometric Series \n                  \n                \n\nLet us define a sequence of terms,\na_{n} = a_{0} r^n\nWhere a_{0}, r \\in \\mathbb{R}, and n \\in \\mathbb{N}.\nr is obviously the ratio of successive terms, and the series looks like,\n\\sum_{n=0}^{\\infty} a_{n} = a_{0} + a_{0}r + a_{0}r^2 + \\dots\nThe nth partial sum of the series has a convenient closed form given by,\ns_{n} = a_{0} \\frac{1-r^n}{1-r}\n\n\n                  \n                  How do we arrive at this expression? r, and then subtract from the original defining equation of the nth partial sum. Only two terms survive on the RHS, and you can divide out by a factor of 1-r to get this expression.\n                  \n                \nJust multiply LHS and RHS of the definition of the nth partial sum with \n\n\n\n                  \n                  Does it converge? |r| &lt; 1, we may easily compute the limit of the nth partial sum as,\n                  \n                \n\n\\lim_{ n \\to \\infty } s_{n} = \\lim_{ n \\to \\infty } a_{0} \\frac{1-r^n}{1-r} = \\frac{a_{0}}{1-r}\nWhich is a finite value. Thus, the geometric series converges.\n\n\n\n\n\n\n                  \n                  The Harmonic Series \n                  \n                \n\nWe define a sequence of terms as,\na_{n} = \\frac{1}{n}\nWhere n \\in \\mathbb{N}.\nThe series looks like,\n\\sum_{n=1}^{\\infty} a_{n} = \\frac{1}{1} + \\frac{1}{2} + \\frac{1}{3} + \\dots + \\frac{1}{n} + \\dots\n\n\n                  \n                  Does it converge? \\lim_{ n \\to \\infty } \\frac{1}{n} = 0.\nNow, let us group the terms in the sum together:\n                  \n                \n\n\\left( 1 + \\frac{1}{2} \\right) + \\left( \\frac{1}{3} + \\frac{1}{4} \\right) + \\left( \\frac{1}{5} + \\frac{1}{6} + \\frac{1}{7} + \\frac{1}{8} \\right) + \\left( \\frac{1}{9} + \\dots + \\frac{1}{16} \\right) + \\dots\nNote that each bracketed sum is of the form: (ignore 1 + \\frac{1}{2}, it is a minor inconsistency and does not affect the limits)\n\\frac{1}{p+1} + \\frac{1}{p+2} + \\dots + \\frac{1}{p+p}\nOf course, each of these p terms are greater than \\frac{1}{2p}. This gives us the lower bound:\n\\frac{1}{p+1} + \\frac{1}{p+2} + \\dots + \\frac{1}{p+p} &gt; \\frac{p}{2p} = \\frac{1}{2}\nSo, we have a sum of these brackets, each bracket greater than \\frac{1}{2}.\nThis leads us to conclude that the harmonic series diverges.\n\n\n\n\nIt is very important to keep track of the series that we have classified as convergent or divergent, as they can then be used in several tests for convergence that we have derived.\nComparison Tests\nLet us have a series defined by the sequence \\{a_{n}\\}_{n=1}^{\\infty} (that we want to test for convergence), and sequence \\{b_{n}\\}_{n=1}^{\\infty} whose series is known to be convergent.\nThen, if the former satisfies,\n0 \\leq a_{n} \\leq b_{n}, \\forall n &gt; N \\in \\mathbb{N}\nthen we can conclude that the series defined by \\sum_{n=1}^{\\infty} a_{n} is convergent.\n\n\n                  \n                  Why does this work? \n                  \n                \n\nAs a rough motivation, we can see that using the Cauchy criteria for convergence |s_{i} - s_{j}| = \\sum_{n=j+1}^{i} a_{n}, which is smaller than the corresponding quantity for the converging series by definition - for a sufficiently large n limit.\nThis allows us to say that the series converges.\n\n\nNote that the converse is also true, i.e. if \\sum_{n=1}^{\\infty} b_{n} diverges and the series in question satisfies,\n0 \\leq b_{n} \\leq a_{n}\nthen \\sum_{n=1}^{\\infty}a_{n} also diverges.\n\n\n                  \n                  Tip\n                  \n                \n\nHere we realise why classifying some standard series like the Geometric and Harmonic series as convergent or divergent serves a useful purpose - it ensures that we can use them in tests like the comparison test to see whether other series are convergent or divergent.\n\n\n\n\n                  \n                  Comparison Test for a divergent series \n                  \n                \n\nLet us define a series for the sequence a_{n} = n^{-p} where p = 0.999.\nWe know that for n \\in \\mathbb{N}, we have,\nn^{-0.999} \\geq n^-1 \nand that b_{n} = n^{-1} are the terms for the Harmonic series - which diverges.\nThus, by the comparison test, we can state that \\sum_{n=1}^{\\infty} a_{n} diverges.\n\n\nCauchy Root Test\nLet us take a series \\sum_{n=1}^{\\infty} a_{n}. If the terms of this series satisfy (for sufficiently large n),\n(a_{n})^{(1/n)} \\leq r &lt; 1\nWhere r \\in \\mathbb{R} is a number independent of n, then we can say that the series is convergent.\nConversely, if we have,\n(a_{n})^{(1/n)} \\geq 1\nfor sufficiently large n, then we can say that the series diverges.\n\n\n                  \n                  Why does this work? \n                  \n                \n\nThis is essentially a special case of the comparison test that makes application easier for power series (note that a_{n}^{1/n} is often easy to compute for the terms of a power series).\nThis can be seen by raising the inequality to the nth power,\na_{n} \\leq r^n &lt; 1\nWhich tells us that the terms of the series in question are always smaller than the corresponding term from a convergent Geometric series! By comparison test, the test holds.\n\n\nD’Alembert (or Cauchy) Ratio Test\nLet us take a series \\sum_{n=1}^{\\infty}a_{n}. For sufficiently large n, if we have,\n\\frac{a_{n+1}}{a_{n}} \\leq r &lt; 1\nWhere r \\in \\mathbb{R} is a number independent of n, then we say that the series converges.\nConversely, if for sufficiently large n we have,\n\\frac{a_{n+1}}{a_{n}} &gt; 1\nwe can conclude that the series in divergent.\nAlternate statement: If we have a series \\sum_{n=1}^{\\infty}a_{n} such that,\n\n\\lim_{ n \\to \\infty } \\frac{a_{n+1}}{a_{n}} &lt; 1: The Series converges\n\\lim_{ n \\to \\infty } \\frac{a_{n+1}}{a_{n}} &gt; 1: The Series diverges\n\\lim_{ n \\to \\infty } \\frac{a_{n+1}}{a_{n}} = 1: The test is inconclusive.\n\nThis test is not as sensitive as the root test (owing to the indeterminacy), but it is very easy to apply. If it fails, we can always move on to a more sensitive test.\n\n\n                  \n                  Why does the indeterminacy appear? \n                  \n                \n\nThe reason is present in the initial statement of the test,\n\\frac{a_{n+1}}{a_{n}} \\leq r &lt; 1\nfor sufficiently large n.\nNote that we may be able to find that \\frac{a_{n+1}}{a_{n}} &lt; 1  for all finite n, but we not be able to find a r &lt; 1 that is independent of n such that \\frac{a_{n+1}}{a_{n}} \\leq r.\n\n\n                  \n                  An example of this indeterminacy \\frac{a_{n+1}}{a_{n}} = \\frac{n}{n+1}\nWhich is always smaller than 1 and larger than \\frac{1}{2} \\forall n \\in \\mathbb{N}.\nBut, it is not possible to find an r that is independent of n, such that it serves as an upper bound for the ratio \\frac{a_{n+1}}{a_{n}} for sufficiently large n.\nThus, we call the test indeterminate in this case.\n                  \n                \nLet us look at the Harmonic Series.\nHere,\n\n\n\n\nCauchy (or Maclaurin) Integral\nIn this test, we compare the series with an integral - i.e. the sum of the area of rectangles of unit width and height equal to terms of the series, with area under the curve of a function.\nLet f(x) be a continuous, monotonically decreasing function, such that f(n) = a_{n}. Then, the series \\sum_{n=1}^{\\infty}a_{n} converges if the integral \\int_{1}^{\\infty} f(x) \\, dx is finite, and diverges if the integral is infinite.\n\n\n                  \n                  Why does this work? \n                  \n                \n\nNote that the partial sums are,\ns_{i} = \\sum_{n=1}^{i}a_{n} = \\sum_{n=1}^{i} f(n)\nBecause the function f(x) is monotonically decreasing, we can always write two inequalities:\ns_{i} \\geq \\int_{1}^{i+1} f(x) \\, dx \nand\ns_{i} - a_{1} \\leq \\int_{1}^{i} f(x) \\, dx \nGraphically, this is obvious - as seen below.\n\nFrom this, we get,\n\\int_{1}^{\\infty} f(x) \\, d \\leq \\sum_{n=1}^{\\infty}a_{n}\\leq \\int_{1}^{\\infty} f(x) \\, d + a_{1}  \ni.e. a classical limit sandwich. If the integral has a finite value, the series must converge, and if the integral diverges the series must also diverge! \n\n\nA particular use for the Integral test\nIt is very useful for setting lower and upper bounds on the remaining terms of a series when some of the series has been summed up.\n\\sum_{n=1}^{\\infty}a_{n} = \\sum_{n=1}^{N}a_{n} + \\sum_{n=N+1}^{\\infty}a_{n}\nWe can now use those two inequalities mentioned before 1 to write,\n\\int_{N+1}^{\\infty} f(x) \\, d \\leq \\sum_{n=N+1}^{\\infty}a_{n} \\leq \\int_{N+1}^{\\infty} f(x) \\, d + a_{N+1}  \nwhich give us upper and lower bounds as required.\nReducing the requirements on f(x)\nWe previously required the function f(x) to be positive and monotonic - which are quite restrictive requirements.\nNow, if f(x) is a function with a continuous derivative, then we have,\n\\sum_{n=N_{1}}^{N_{2}} f(n) = \\int_{N_{1}}^{N_{2}} f(x) \\, dx + \\int_{N_{1}}^{N_{2}} (x-\\lfloor x \\rfloor ) f&#039;(x) \\, dx \\tag{1} \\label{1}\nHere, \\lfloor x \\rfloor represents the “floor” of x, i.e. the largest integer smaller or equal to x, and f&#039;(x) is the derivative of f with respect to x.\nNote that x - \\lfloor x \\rfloor = \\{x\\}, or the fractional part of x. It varies like a saw-tooth, rising linearly from an integer to the next and then dropping abruptly to zero.\nWhy is this relevant? If both of the integrals in this equation converge, then the infinite series also converges. If exactly one of the integrals diverges, then the series diverges. If both of the integrals diverge, we have a tricky situation - the test is indeterminate unless it can be shown that the divergences of the integrals “cancel out”.\n\n\n                  \n                  How do we arrive at those integrals? \n                  \n                \n\nLet us reason backwards, and show that RHS is equal to LHS.\n\nUsing integration by parts, we see that \\int_{N_{1}}^{N_{2}} xf&#039;(x) \\, dx = N_{2}f(N_{2}) - N_{1}f(N_{1}) - \\int_{N_{1}}^{N_{2}} f(x) \\, dx.\nOn the floor function integral, we see, \\int_{N_{1}}^{N_{2}} \\lfloor x \\rfloor f&#039;(x) \\, dx = \\sum_{n=N_{1}}^{N_{2} - 1} n \\int_{n}^{n+1} f&#039;(x) \\, dx = \\sum_{n=N_{1}}^{N_{2}-1}n[f(n+1)-f(n)].\nThis final expression simplifies into,\n\n -\\sum_{n=N_{1}+1}^{N_{2}} f(n) - N_{1}f(N_{1}) + N_{2}f(N_{2})\nAdding them together, we see that everything cancels out nicely and we are left with the original result.\n\n\nAlternatively, we can also use the integral “decomposition”:\n\\sum_{n=N_{1}+1}^{N_{2}}f(n) = \\int_{N_{1}}^{N_{2}} f(x) \\, dx + \\int_{N_{1}}^{N_{2}} \\left( x - \\lfloor x \\rfloor - \\frac{1}{2} \\right) f&#039;(x) \\, dx + \\frac{1}{2}[f(N_{2}) - f(N_{1})]  \\tag{2} \\label{3}\nThis one has the added benefit of being symmetrical about zero (the saw tooth has been shifted). We may derive it in the same method as the one before.\nEquations \\eqref{1} and \\eqref{3} can be used in alternating series, and those with irregular sign sequences owing to the lack of monotonicity requirement.\n\n\n                  \n                  Riemann Zeta Function \n                  \n                \n\nWe define the Riemann Zeta Functions as,\n\\zeta (p) = \\sum_{n=1}^{\\infty} n^{-p}\nLet us use the integral test that we just developed on this.\n\\int_{1}^{\\infty} x^{-p} \\, dx = \\frac{x^{-p+1}}{-p+1} \\lvert_{x=1}^{\\infty} , p \\neq 1  \\text{ or } \\ln(x) \\lvert_{x=1}^{\\infty}, p = 1\nThe integral is divergent for p \\leq 1 and is convergent for p&gt;1 - this is an independent proof that the Harmonic series diverges logarithmically (which means it diverges very slowly, like a logarithm).\n\n\n                  \n                  Euler Mascheroni Constant \\ln converge as expected, their difference does!\n                  \n                \n\n\\gamma = \\lim_{ n \\to \\infty } \\left( \\sum_{m=1}^{n} m^{-1} - \\ln(n) \\right)\nWhich is known as the Euler-Mascheroni constant.\n\n\n\n\n\n\n                  \n                  A slowly diverging function \n                  \n                \n\nConsider,\n\\sum_{n=2}^{\\infty} \\frac{1}{n \\ln(n)}\nClearly, the denominator here grows just a tiny bit faster than when it was just the n. Using the integral test on it,\n\\int_{2}^{\\infty} \\frac{1}{x \\ln(x)} \\, dx = \\ln(\\ln(x)) |_{x=2}^{\\infty} \nWhich is divergent, meaning that the series is also divergent.\nThis series diverges even slower than the Harmonic series (which already diverges very slowly - the sum of the first million terms or so of the Harmonic series is less than 15).\n\n\nMore sensitive tests\nFootnotes\n\n\nCheck the callout just above. ↩\n\n\n"},"Mathematics/Mathematical-Methods-in-Physics/Mathematical-Methods-in-Physics-(Home)":{"title":"Mathematical Methods in Physics (Home)","links":["Mathematics/Mathematical-Methods-in-Physics/Infinite-Series","Series-of-Functions","Mathematical-Induction","Operations-on-Series-Expansions-of-Functions","A-few-important-series","Vectors","Complex-numbers-and-Functions","Derivatives-and-Extrema","Evaluations-of-Integrals","Dirac-Delta-Function","Mathematics/Mathematical-Methods-in-Physics/Vector-Calculus"],"tags":["mathematics","methods"],"content":"List of topics (in a rough logical order)\n\nSome preliminaries:\n\nInfinite Series\nSeries of Functions\nMathematical Induction\nOperations on Series Expansions of Functions\nA few important series\nVectors\nComplex numbers and Functions\nDerivatives and Extrema\nEvaluations of Integrals\nDirac Delta Function\n\n\nVector Calculus\n"},"Mathematics/Mathematical-Methods-in-Physics/Vector-Calculus-in-Curvilinear-Coordinates":{"title":"Vector Calculus in Curvilinear Coordinates","links":[],"tags":["curvilinear","vector","calculus","mathematics"],"content":"We will going over the three fundamental theorems of vector calculus in generalised curvilinear coordinates.\nNotation\nWe identify a point in space by some 3-tuple of its “coordinates” - (u,v,w).\nWe assume that the system is based on some orthogonal basis, i.e. the unit vectors \\mathbf{\\hat{u}}, \\mathbf{\\hat{v}}, \\mathbf{\\hat{w}} are pointing in mutually orthogonal directions.\n\n\n                  \n                  Note\n                  \n                \n\nIn general curvilinear orthogonal coordinates, the unit vector are supposed to be functions of the coordinates themselves. This is due to the fact that unlike the Cartesian system (which also qualifies as a curvilinear orthogonal coordinate system), it is not guaranteed that the unit vectors will point in the same direction at all points\n\n\nNow, any 3D vector can be expressed using its coordinates in this vector space. In particular, we may attempt to represent the infinitesimal displacement vector from (u,v,w) to (u + du, v + dv, w + dw) as:\nd \\mathbf{l} = f du \\mathbf{\\hat{u}} + g dv \\mathbf{\\hat{v}} + h dw \\mathbf{\\hat{w}}\nwhere f, g, h are some functions of coordinates, and a characteristic of the coordinate system that we choose - i.e. f=g=h=1 for Cartesian coordinate system.\nThese three functions can tell you all that you need to know about a particular coordinate system.\nGradient\nLet t (u,v,w) be a scalar function of the coordinates in the space we just described. If we carry out an infinitesimal change in coordinates from (u,v,w) \\to (u+du,+dv,w+dw) , t will change by an amount given by:\ndt = \\frac{ \\partial t }{ \\partial u } du + \\frac{ \\partial t }{ \\partial v } dv + \\frac{ \\partial t }{ \\partial w } dw\nas a standard result from the definition of partial derivatives. We can represent this as a dot product, given by:\ndt \\equiv \\nabla t \\cdot d \\mathbf{l} = (\\nabla t)_{u} f du + (\\nabla t)_{v} g dv + (\\nabla t)_{w} h dw\nTo make this agree with the partial derivative result, we have to adopt the following definitions:\n(\\nabla t)_{u} = \\frac{1}{f} \\frac{ \\partial t }{ \\partial u }, (\\nabla t)_{v} = \\frac{1}{g} \\frac{ \\partial t }{ \\partial v }, (\\nabla t)_{w} = \\frac{1}{h} \\frac{ \\partial t }{ \\partial w }   \nas can be seen by a simple substitution.\nThus, we may define:\n\n\n                  \n                  Gradient \n                  \n                \n\nThe gradient of a scalar function of coordinates in a vector space is given by:\n\\nabla t \\equiv \\frac{1}{f} \\frac{ \\partial r }{ \\partial u } \\mathbf{\\hat{u}} + \\frac{1}{g} \\frac{ \\partial t }{ \\partial v } \\mathbf{\\hat{v}} + \\frac{1}{h} \\frac{ \\partial t }{ \\partial w } \\mathbf{\\hat{w}}\n\n\nIf we know the functions f,g,h for a particular coordinate system, we can easily construct the gradient.\nFundamental theorem of gradients\nFrom the equation that defines dt using the gradient, we can see that a total change in t going from a point \\mathbf{a} to a point \\mathbf{b} is given by:\nt(\\mathbf{b}) - t(\\mathbf{a}) = \\int_{\\mathbf{a}}^{\\mathbf{b}}  \\, dt = \\int_{\\mathbf{a}}^{\\mathbf{b}} (\\nabla t) \\cdot\\, d\\mathbf{l}  \nThis result is a case of a clear substitution combined with the fundamental theorem of calculus, so there is nothing to prove here in this context.\nDivergence\nNow, let us a have a vector function of the coordinates, given by:\n\\mathbf{A}(u,v,w) = A_{u}(u,v,w) \\mathbf{\\hat{u}} + A_{v}(u,v,w) \\mathbf{\\hat{v}} + A_{w}(u,v,w) \\mathbf{\\hat{w}}\nWhere A_{u}, A_{v}, A_{w} are component scalar functions.\nA common thing to do with such a function is the find the integral \\oint \\mathbf{A} \\cdot d \\mathbf{a} over some surface. In general, the surface might look like this:\n\n(Source: Griffiths, Introduction to Electromagnetism - Figure A.2)\nNote that the surface has been generated by incrementing the coordinates infinitesimally, in sequence.\nThe sides of this “rectangular” solid is given by dl_{u} = f du, dl_{v} = g dv, dl_{w} = h dw. Thus, the volume of the solid is given by:\nd \\tau = dl_{u} dl_{v} dl_{w} = (fgh) du dv dw\nNow, we find the components of \\mathbf{A}\\cdot d \\mathbf{a} on each face - for the “front” face, we have:\nd \\mathbf{a} = - (gh) dv dw \\mathbf{\\hat{u}}\nand thus,\n\\mathbf{A}\\cdot d \\mathbf{a} = - (ghA_{u}) dv dw\nThe back surface is identical to this one, and just differs in the sign. But we must note that in the case of the back surface, the function is to be evaluated at u+du instead of u. For any differentiable function, we have:\nF(u+du) - F(u) = \\frac{d f}{du} du\ntaking du to be infinitesimal.\nWe note that due to the sign flipping on the back and the front surface, combined with the different values of u at which the function is evaluated, we have the RHS of the above equation in terms of A_{u}. Adding the contributions from the front and back surfaces, we thus get:\n\\left[  \\frac{ \\partial  }{ \\partial u } (ghA_{u})  \\right] du dv dw = \\frac{1}{fgh} \\frac{ \\partial  }{ \\partial u } (gh A_{u}) d \\tau\nCarrying out the same procedure for the top-bottom and left-right surface pairs, we get:\n\\oint \\mathbf{A} \\cdot d \\mathbf{a} = \\frac{1}{fgh} \\left[  \\frac{ \\partial  }{ \\partial u } (ghA_{u}) + \\frac{ \\partial  }{ \\partial v } (fhA_{v}) + \\frac{ \\partial  }{ \\partial w } (fgA_{w})  \\right] d \\tau\nThe coefficient of d \\tau serves the role of specifying the divergence of \\mathbf{A} in the given curvilinear coordinates. Thus, we may write:\n\\nabla \\cdot\\mathbf{A} \\equiv \\frac{1}{fgh} \\left[  \\frac{ \\partial  }{ \\partial u } (ghA_{u}) + \\frac{ \\partial  }{ \\partial v } (fhA_{v}) + \\frac{ \\partial  }{ \\partial w } (fgA_{w})  \\right] \nand we may rewrite the surface integral as:\n\\oint \\mathbf{A}\\cdot d \\mathbf{a} = (\\nabla \\cdot \\mathbf{A}) d \\tau \nNote: this does not prove the divergence theorem, as it says something about infinitesimal volumes only! It is reasonable to assume that a finite solid can be split into many infinitesimal solids, and thus the relation holds - but that is not the case, as the LHS of the equation in that case would have terms that contribute to not just the outside surface of the finite solid but also many more surfaces.\nLuckily, we can see that d \\mathbf{a} always points outwards, and any surface that is not a part of the external surface of the finite solid will necessarily have to be facing another surface with a d \\mathbf{a} pointing in the opposite direction. Thus, all the extra contributions cancel out neatly, and we are left with the result of the divergence theorem:\n\n\n                  \n                  Divergence Theorem \n                  \n                \n\nFor a vector function \\mathbf{A}, and finite volume V bounded by a closed surface S, we have:\n\\oint_{S} \\mathbf{A} \\cdot d \\mathbf{a} = \\int_{V} (\\nabla \\cdot \\mathbf{A}) d \\tau\n\n\n(Note that this holds for any region V - a more detailed proof is omitted here)\nCurl\nTo arrive at the form of curl, we have to look at the line integral:\n\\oint \\mathbf{A} \\cdot d\\mathbf{l}\naround an infinitesimal loop generated by starting at (u,v,w) and successively increasing u and v, all the while holding w constant. We imagine this surface (again, in the infinitesimal limit) to be a rectangle with the dimensions:\ndl_{u} = f du, dl_{v} = g dv\nTherefore, the area of the loop is given by:\nd \\mathbf{a} = (fg) du dv\n\nWe make an assumption: the coordinate system is right-handed. Thus, \\mathbf{\\hat{w}} points out of the page in this figure. We choose this as the positive direction of d \\mathbf{a}, and we follow the anti-clockwise traversal of the loop as shown.\nWe look at each segment of the loop. Along the bottom segment, we have:\nd \\mathbf{l} = f du \\mathbf{\\hat{u}}\nand thus, we get,\n\\mathbf{A} \\cdot d \\mathbf{l} = (f A_{u}) du\nOn the top, the sign is reversed for the d\\mathbf{l} component and \\mathbf{A} is not evaluated at (v+dv) instead of v. Adding the contributions of this top-bottom pairs, we get:\n[ -(f A_{u}) \\lvert_{v+dv} + (fA_{u}) \\lvert_{v}] du = - \\left[  \\frac{ \\partial  }{ \\partial v } (f A_{u})  \\right] du dv\nCarrying out the same manipulation on the right-left segment pair, we get:\n\\left[  \\frac{ \\partial  }{ \\partial u } (g A_{v})  \\right] du dv\nCombing the terms,\n\\oint \\mathbf{A} \\cdot d \\mathbf{l} = \\left[  \\frac{ \\partial  }{ \\partial u } (g A_{v}) - \\frac{ \\partial  }{ \\partial v } (f A_{u})  \\right] du dv = \\frac{1}{fg} \\left[  \\frac{ \\partial  }{ \\partial u } (gA_{v}) - \\frac{ \\partial  }{ \\partial v } (fA_{u})  \\right] \\mathbf{\\hat{w}} \\cdot d \\mathbf{a}\nThe coefficient of d \\mathbf{a} on the RHS gives us the \\mathbf{\\hat{w}} component of the curl. Constructing the \\mathbf{\\hat{u}}, \\mathbf{\\hat{v}} components using the same method, we arrive at a definition for the curl:\n\\nabla \\times \\mathbf{A} = \\frac{1}{gh} \\left[  \\frac{ \\partial  }{ \\partial v } (h A_{w}) - \\frac{ \\partial  }{ \\partial w } (gA_{v})  \\right] \\mathbf{\\hat{u}} + \\frac{1}{fh} \\left[  \\frac{ \\partial  }{ \\partial w } (fA_{u}) - \\frac{ \\partial  }{ \\partial u } (h A_{w})  \\right] \\mathbf{\\hat{v}} + \\frac{1}{fg} \\left[  \\frac{ \\partial  }{ \\partial u } (gA_{v}) - \\frac{ \\partial  }{ \\partial v } (fA_{u})  \\right] \\mathbf{\\hat{w}}\nGiving us the familiar result:\n\\oint \\mathbf{A} \\cdot d \\mathbf{l} = (\\nabla \\times \\mathbf{A}) \\cdot d\\mathbf{a}\nThis is not yet Stoke’s theorem, as it says something about an infinitesimal loop only. Like in the case of the divergence theorem, in this case too we can argue that any finite loop can be chopped in to infinitesimal loops such that all segments of the loop apart from the segments at the boundaries cancel each other out by virtue of being traversed in opposite directions for loop touching each other.\nThis give us the Stoke’s theorem,\n\n\n                  \n                  Stokes&#039; Theorem \n                  \n                \n\nFor a finite loop L that closes a surface of area s, we have:\n\\oint_{L} \\mathbf{A} \\cdot d \\mathbf{l} = \\int_{S} (\\nabla \\times \\mathbf{A}) \\cdot d \\mathbf{ a} \n\n\nLaplacian\nThe form of this operator for the generalised curvilinear coordinate system can be derived from the fact that is a scalar, and the divergence of a gradient. Using the previously derived formulae for both of those operations, we derive the Laplacian as,\n\\nabla ^2 t = \\frac{1}{fgh} \\left[  \\frac{ \\partial  }{ \\partial u } \\left( \\frac{gh}{f} \\frac{ \\partial t }{ \\partial u }  \\right) + \\frac{ \\partial  }{ \\partial v } \\left( \\frac{fh}{g} \\frac{ \\partial t }{ \\partial v }  \\right) + \\frac{ \\partial  }{ \\partial w } \\left( \\frac{fg}{h} \\frac{ \\partial t }{ \\partial w }  \\right)  \\right]\nReferences\n\nDavid J. Griffiths, Introduction to Electromagnetism\n"},"Mathematics/Mathematical-Methods-in-Physics/Vector-Calculus":{"title":"Vector Calculus","links":["Mathematics/Mathematical-Methods-in-Physics/Vector-Calculus-in-Curvilinear-Coordinates","Helmholtz-Theorem"],"tags":["mathematics","vector","calculus"],"content":"List of topics\n\nVector Calculus in Curvilinear Coordinates\nHelmholtz Theorem\n"},"Quantum-Mechanics/Axioms-of-Quantum-Mechanics":{"title":"Axioms of Quantum Mechanics","links":[],"tags":["axioms","QM","Quantum"],"content":"The following are the axioms of Quantum Mechanics -\n\n\nThe properties of quantum systems are completely defined by the specification of its state vector, denoted generally by \\ket{\\psi}. The state vector is an element of a complex Hilbert Space \\mathbb{H}, called the space of states.\n\n\nWith every physical property \\mathcal{A}, there exists a corresponding linear, Hermitian operator A called an observable, which acts in the Hilbert space \\mathbb{H}.\n\nThe eigenvalues of these Hermitian operators are values of the physical properties.\n\n\n\n(Born Rule) If \\ket{\\psi} is the vector in \\mathbb{H} representing the state of the system, and \\ket{\\phi} represents a particular physical state of the system, we can define a probability P(\\ket{\\psi},\\ket{\\phi}) for finding \\ket{\\psi} in the state \\ket{\\phi}. This is given by,\n\n\nP(\\ket{\\psi},\\ket{\\phi}  ) = |\\braket{ \\psi | \\phi } |^{2}\nWhere \\braket{ \\cdot | \\cdot } denotes the inner product defined on the Hilbert Space.\n\n(Wave function collapse) If A is an observable with the eigenvalues listed in the set \\{ a_{n} \\} and the eigenvectors listed in the set \\{ \\ket{n} \\}, and we have a system in a given state \\ket{\\psi}, the probability of obtaining a_{n} as the “outcome” of the measurement of \\mathcal{A} (the physical property corresponding to the observable), i.e. on the action of A on \\ket{\\psi} is given by,\n\nP(a_{n}) = |\\braket{ n | \\psi } |^{2}\nAfter such a measurement operation is done, the system is left in the state \\ket{n}, i.e the wave function \\ket{\\psi} “collapses” to that state.\n\nThe time-evolution of a closed system as described in Quantum Mechanics is unitary, i.e. reversible. The evolution is given by the time-dependent Schrodinger equation -\n\ni \\hbar \\frac{\\partial \\ket{\\psi}}{\\partial t} = H \\ket{\\psi} \nWhere H is the Hamiltonian of the system, \\hbar is the reduced Planck constant, and i is \\sqrt{ -1 }.\nReferences\n\nQuantum Theory of Radiation Interaction - MIT OCW, Fall 2012\n"},"Quantum-Mechanics/Non-Relativistic-Quantum-Mechanics/Conservation-of-probability-current-associated-with-wavefunction-(Proof)":{"title":"Conservation of probability current associated with wavefunction (Proof)","links":["Quantum-Mechanics/The-Schrodinger-Equation"],"tags":["Quantum","Probability"],"content":"Claim\nWe claim that for the definition of probability density \\rho(x,t) and probability current J(x,t) as given in Probability (Born interpretation) satisfies the following equation:\n\\frac{ \\partial J }{ \\partial x } + \\frac{ \\partial \\rho }{ \\partial t } = 0 \n(1D version).\nProof\nWe simply plug in the expressions in terms of the wavefunction \\Psi(x,t) into RHS:\n\\frac{ \\partial  }{ \\partial x } \\left( \\frac{\\hbar}{m} \\mathrm{Im} \\left( \\Psi^{*} \\frac{ \\partial \\Psi }{ \\partial x }  \\right)\\right) + \\frac{ \\partial  }{ \\partial t } (\\Psi^{*}\\Psi)\n\\implies \\frac{\\hbar}{m} \\mathrm{Im}\\left( \\frac{ \\partial \\Psi^{*} }{ \\partial x } \\frac{ \\partial \\Psi }{ \\partial x } + \\Psi^{*} \\frac{ \\partial^{2}\\Psi }{ \\partial x^{2} } \\right) + \\frac{ \\partial \\Psi^{*} }{ \\partial t } \\Psi + \\Psi^{*} \\frac{ \\partial \\Psi }{ \\partial t }\nNow, plugging in the SE (and conjugate of SE) will give us an expression that is zero.\n(Proved(?) :) )"},"Quantum-Mechanics/Non-Relativistic-Quantum-Mechanics/Non-Relativistic-Quantum-Mechanics-(Home)":{"title":"QM 2 (Home)","links":["Quantum-Mechanics/Non-Relativistic-Quantum-Mechanics/Wave-Mechanics-(QM)"],"tags":["Quantum","Home"],"content":"Topics (in logical order)\n\nWave Mechanics (QM)\n\n"},"Quantum-Mechanics/Non-Relativistic-Quantum-Mechanics/SE-preserves-normalization-(Proof)":{"title":"Schrodinger Equation preserves the normalization of a wavefunction","links":[],"tags":["Quantum","Proof"],"content":"Claim\nGiven a valid 1D wavefunction \\Psi(x,t) (i.e. a solution to the Schrodinger equation) that is normalized to unity at some time t_{0},\n\\int_{- \\infty}^{\\infty} \\lvert \\Psi(x,t_{0}) \\rvert ^{2} \\, dx = 1 \nwe claim that the wavefunction remains normalized to unity \\forall t,\n\\int_{- \\infty}^{\\infty} \\lvert \\Psi(x,t) \\rvert ^{2} \\, dx = 1 , \\forall t \nProof\nWe alter the claim slightly to claim that given the initial normalization, we have:\n\\frac{d}{dt} \\int_{-\\infty}^{\\infty} \\lvert \\Psi(x,t) \\rvert ^{2} \\, dx = 0 \nNow, we know that:\n\\lvert \\Psi(x,t) \\rvert ^{2} = \\Psi^{*}(x,t) \\Psi(x,t)\nPlugging this in the LHS of the claimed equality, and interchanging the integral with the derivative (as they are carried with respect to different independent variables):\n\\begin{aligned}\n\\frac{d}{dt} \\int_{-\\infty}^{\\infty} \\lvert \\Psi(x,t) \\rvert ^{2} \\, dx \\\\\n\\implies \\int_{-\\infty}^{\\infty} \\left( \\frac{\\partial \\Psi^{*}}{\\partial t} \\Psi + \\frac{\\partial\\Psi}{\\partial t} \\Psi^{*}  \\right) \\, dx \n\\end{aligned}\nNow, we can see that this equation has time derivatives of the wavefunction and its complex conjugate - which means that we can substitute the SE here. First, we determine the Complex conjugate of the SE:\n-i \\hbar \\frac{ \\partial \\Psi^{*}  }{ \\partial t } (x,t) = \\left( - \\frac{\\hbar^{2}}{2m} \\frac{ \\partial^{2} }{ \\partial x^{2} } + V(x,t)  \\right) \\Psi^{*}(x,t)\nPutting this in the previous expression, we get:\n\\implies \\frac{i}{\\hbar} \\int_{-\\infty}^{\\infty} \\left(  \\left( -\\frac{\\hbar^{2}}{2m} \\frac{ \\partial^{2} }{ \\partial x^{2} } + V \\right) \\Psi^{*} \\Psi + \\left(\\frac{\\hbar^{2}}{2m} \\frac{ \\partial^{2} }{ \\partial x^{2} } - V \\right) \\Psi^{*} \\Psi\\right) \\, dx \nThe V terms neatly cancel out, as they only act via multiplication on the wavefunction. After some cleanup, we get:\n\\implies \\int_{-\\infty}^{\\infty}  \\frac{ \\partial  }{ \\partial x } \\left[  \\frac{i \\hbar}{2m} \\left( \\Psi^{*} \\frac{ \\partial \\Psi }{ \\partial x } - \\frac{ \\partial \\Psi^{*} }{ \\partial x } \\Psi \\right)  \\right] dx \nSo, the intergal ends up simplifying to:\n\\frac{i \\hbar}{2m} \\left[\\Psi^{*} \\frac{ \\partial \\Psi }{ \\partial x } - \\frac{ \\partial \\Psi^{*} }{ \\partial x } \\Psi \\right]_{-\\infty}^{\\infty} \nWe make two very crucial assumptions, so that this expression neatly goes to zero:\n\nThe wavefunction dies off at \\pm \\infty, i.e.: \\lvert \\Psi(x,t) \\rvert \\to 0 as \\lvert x \\rvert \\to \\pm \\infty. This ensures that the wavefunction remains square-normalizable over the entire domain.\n\\frac{ \\partial \\Psi }{ \\partial x }is bounded as \\lvert x \\rvert \\to \\pm \\infty. This is a more general demand than asking the derivative to go to zero at \\pm \\infty.\nUnder these two assumptions, the expression goes to zero. Therefore, we can say:\n\n \\frac{d}{dt} \\int_{-\\infty}^{\\infty} \\lvert \\Psi(x,t) \\rvert ^{2}  \\, dx = 0 \\text{ ( Proved :) )} "},"Quantum-Mechanics/Non-Relativistic-Quantum-Mechanics/Stationary-Solutions":{"title":"Stationary Solution","links":[],"tags":["Quantum"],"content":"In many problems, we do not have a potential with time dependence in the Hamiltonian, i.e. \\frac{ \\partial V }{ \\partial t } = 0. In this case, the potential is simply a function of the position.\nNow, the SE can we written more compactly as:\ni \\hbar \\frac{ \\partial \\Psi }{ \\partial t } (x,t) = \\hat{H} \\Psi(x,t)\nWhere \\hat{H} represents the Hamiltonian operator for the system.\nIn general, the Hamiltonian operator has the form:\n\\hat{H} = - \\frac{\\hbar^{2}}{2m}\\frac{ \\partial^{2} }{ \\partial x^{2} } + V(x)\nTherefore it acts on functions from the space of complex functions, and returns a complex function. V acts only by multiplication. Also, not that here \\hat{H} is time-independent.\n\n\n                  \n                  Stationary State \n                  \n                \n\nA stationary state of energy E in \\mathbb{R}is a state \\Psi(x,t) that takes on the form:\n\\Psi(x,t) = e^{ -(i E t)/\\hbar } \\psi(x)\nWhere \\psi(x) \\in \\mathbb{C} is a function of x only, that serves as a solution to the Time-independent Schrodinger equation (TISE).\n\n\nNote that all of the time-dependence of the Stationary state is carried in an exponential factor that lies out in the front. Such a state is called a Stationary state because the physical observables off the state are time independent. A simple example that shows this is the expression for the probability density for such a stationary state:\n\\rho(x,t) = \\lvert \\Psi(x,t) \\rvert ^{2} = e^{ (iEt)/\\hbar } \\psi ^{*}(x) e^{ -(iEt)/\\hbar }\\psi(x) = \\lvert \\psi(x) \\rvert ^{2}\nWhat if the energy E had been a complex number?\nLet us assume:\nE = E_{0} + i \\Gamma, E_{0}, \\Gamma \\in \\mathbb{R}\nthen, it can be seen that the time dependence would not drop out, as there would not be opposite signs in both of the exponential terms:\n\\rho(x,t) = e^{ -(2 \\Gamma t)/\\hbar } \\lvert \\psi(x) \\rvert ^{2}\nThe normalization of such a state can not be preserved in time under time-evolution dictated by the SE. So, such a state is not acceptable."},"Quantum-Mechanics/Non-Relativistic-Quantum-Mechanics/Wave-Mechanics-(QM)":{"title":"Wave Mechanics (QM)","links":["Quantum-Mechanics/The-Schrodinger-Equation","Quantum-Mechanics/Non-Relativistic-Quantum-Mechanics/Stationary-Solutions","Properties-of-eenergy-eigenstates-in-one-dimension","The-nature-of-the-spectrum","Variational-Principle-(QM)","Position-and-momentum"],"tags":["Quantum","wave"],"content":"Topics (in logical order)\n\nThe Schrodinger Equation\nStationary Solutions\nProperties of eenergy eigenstates in one dimension\nThe nature of the spectrum\nVariational Principle (QM)\nPosition and momentum\n"},"Quantum-Mechanics/Quantum-Information-and-Computation/Bennet's-resolution-of-Maxwell's-Demon":{"title":"Bennet's resolution of Maxwell's Demon","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Landauers-Principle","Quantum-Mechanics/Quantum-Information-and-Computation/Reversible-computation","Maxwell's-Demon","2nd-Law-of-Thermodynamics"],"tags":["infomation","thermodynamics","computation"],"content":"From the insights obtained from both Landauers Principle and Reversible computation (Bennet’s method), Bennet was able to reconcile Maxwell’s Demon (the actual thought experiment is not described on this page) with the 2nd Law of Thermodynamics.\nLooking at the demon using information theory\nIf the demon is to discern between a “fast” and a “slow” particle and open the shutter between the partitions based on this information - the demon must collect and store information about the particles of gas. It must also compute using this information to know when to open and close the gate. If the demon has a finite memory, the demon can not continue to cool the gas indefinitely - at some point it must erase its memory to carry on, which has an energy cost. So work is done to transfer heat from a body at a lower temperature to a body at a higher temperature, and the 2nd Law of Thermodynamics is not violated!\n\n\n                  \n                  Note\n                  \n                \n\nIf we want to account for the energy expenditure before the demon erases its memory, we must associate some entropy with the information recorded by the demon.\nSzilard, and some history\nThis particular resolution to the Maxwell’s Demon problem was largely anticipated by Leo Szilard in 1929 - he invented the concept of a bit of information (the term “bit” was coined later by Tukey) and he associated the entropy \\Delta S = k \\ln 2 with the acquisition of a bit of information. Note that Szilard did not seem to have arrived at Landauer’s Principle - that it was the erasure of the bit that carries the energy cost."},"Quantum-Mechanics/Quantum-Information-and-Computation/Efficient-Quantum-Algorithms":{"title":"Efficient Quantum Algorithms","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Information","Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Complexity"],"tags":["QM","computation","Quantum"],"content":"From what we have seen in Quantum Information, it is clear that Quantum Theory will have profound effects on our understanding of computation.\nIn April 1994, Peter Shor demostrated that, in principle, a Quantum computer can factor a large number “efficiently”.\n\n\n                  \n                  Note\n                  \n                \n\nFactoring (i.e. findding the prime factors) of a large composite number is an example of an intractable problem. It has these properties:\n\nThe solution is very “easy” to verify once found.\nThe solution is “hard” to find\n\nIf p and q are large prime numbers, the product n = pq is something that can be computed very quickly (No. of required operations is roughly \\log_{2}p \\cdot \\log_{2}q). But, if we are given just n, it is “hard” to find p and q.\nIt has been conjectured (but not proved) that the number of operations required to find the factors is superpolynomial in \\log n, i.e. as n increases the number of operations increases faster than any power of \\log n.\nThe best known algorithm for factoring, the “Number Field Sieve” requires roughly \\exp\\left( c(\\ln n)^{\\frac{1}{3}}  (\\ln (\\ln n))^{\\frac{2}{3}} \\right), where c \\approx 1.9.\nUsing this algorithm, we can estimate that factoring a 400 digit number would take about 10^{10} years - the age of the universe (assuming a computer that takes 1 month to factor a 130 digit number)\n\n\nIn the context of Complexity theory, an “intractable” problem essentially means a problem that can not solved in a time bounded by a polynomial in the size of the input (in this case, that is \\log n). This is practically important in topics like cryptography (e.g. RSA cryptography).\nShor’s Result\nShor showed that a Quantum computer can factor in polynomial time! More precisely, in time:\nO[(\\ln n)^3]\nUsing the same computer, this Quantum Algorithm can factor a 400 digit number in just 3 years. the harder the problem, the greater the advantage enjoyed by the Quantum computer.\nNext: Quantum Complexity"},"Quantum-Mechanics/Quantum-Information-and-Computation/Introduction-to-Quantum-Information-and-Computation":{"title":"Introduction to Quantum Information and Computation","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Physics-of-Information","Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Information","Quantum-Mechanics/Quantum-Information-and-Computation/Efficient-Quantum-Algorithms","Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Complexity","Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Parallelism","Quantum-Mechanics/Quantum-Information-and-Computation/New-classifications-of-complexity","Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Errors","Quantum-Error-Correcting-Codes","Quantum-Hardware"],"tags":["Quantum","computation","information"],"content":"Topics (in order)\n\nPhysics of Information\nQuantum Information\nEfficient Quantum Algorithms\nQuantum Complexity\nQuantum Parallelism\nNew classifications of complexity\nQuantum Errors\nQuantum Error-Correcting Codes\nQuantum Hardware\n\nSummary\nReferences\n\nMost of these notes at the moment (March 2025) are drawn from John Preskill’s Lecture Notes on Quantum Information and Computation, Physics 229 at Caltech. A pdf of the notes can be found here\n"},"Quantum-Mechanics/Quantum-Information-and-Computation/Landauers-Principle":{"title":"Landauer's Principle","links":[],"tags":["information","thermodynamics","QM"],"content":"In 1961 Rolf Landauer pointed out that the erasure of information is necessarily a dissipative process. He saw that erasure of information always involves the compression of phase space, and thus it is irreversible.\nExample: Suppose we have a box with a partition in the middle, separating the box into “Left” and “Right” sections. We can store a bit of information in this box by keeping one molecule of gas in either the “Right” or the “Left” section. To erase the information here, we can choose to bring this molecule to the “Left” of the box, regardless of where it was originally (and then forget where we brought it from; that is essentially the “erasure”). We can do this by - 1. Removing the partition. This causes this “one molecule gas” to expand into the entire box, 2. Putting in a movable partition at the right wall of the box, and then moving it to “compress” the “one molecule gas” into the “Left” section. Now, in doing so, we do some work! If the process is isothermal (at some temperature T), then the work done on the box-gas system is given exactly by W = T \\Delta S = k T \\ln 2.\n\n“If I am to erase information, someone will have to pay the power bill” - John Preskill.\n"},"Quantum-Mechanics/Quantum-Information-and-Computation/New-classifications-of-complexity":{"title":"New classifications of complexity","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Efficient-Quantum-Algorithms","Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Errors"],"tags":["complexity","computation","Quantum"],"content":"Given an infinite amount off memory and an infinite amount of time, all classical computers can compute anything - they are Turing complete, or Universal computers.\nClassical complexity theory concerns itself with determining whether a particular problem is “hard” or “easy” - depending on how much memory and time is required to solve the problem by a classical computer. But how can such classifications be universal, when we have not specified the hardware on which it is to be solved? For these classifications to be useful, they must be universal.\nTo arrive at such a description, we first define a few terms:\n\n\n                  \n                  Some terms from complexity theory \n                  \n                \n\nFor any algorithm A, we can define a complexity function T_{A}(N), where N is the size of the input given to A in bits. T_{A}(N) gives us the number of elementary steps/operations that are required for the algorithm to compute the output. Thus, it gives us an idea of the “time” required for the computation.\n\n\nWe say that A is polynomial time if:\nT_{A}(N) \\leq \\text{Poly}(N)\nWhere \\text{Poly}(N) denotes a polynomial in N. Essentially, this means that the number of operations required to compute the result does not grow faster than a power of N.\nAnything that is not polynomial time can be called non-polynomial time.\nThis classification scheme of polynomial time and non-polynomial time is a reasonable universal classification for what qualifies as “easy” or “hard”.\nWhy is this universal? We can arrive at that from a fundamental result from Computer Science: One universal classical computer can simulate another with (at worst) a polynomial overhead. This means that if something runs on one classical computer in polynomial time, it can always be run in polynomial on all universal classical computers. Since both computers are capable of such emulation of the other, they can agree on what is polynomial time.\nWe suspect (from Shor’s Result) that Quantum computers (which represent the physical reality of what can be computed) do not obey this result that characterises the capabilities of classical Turing machines.\nNext: Quantum Errors"},"Quantum-Mechanics/Quantum-Information-and-Computation/Physics-of-Information":{"title":"Physics of Information","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Landauers-Principle","Quantum-Mechanics/Quantum-Information-and-Computation/Reversible-computation","Quantum-Mechanics/Quantum-Information-and-Computation/Bennet's-resolution-of-Maxwell's-Demon","Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Information"],"tags":["infomation","QM","Quantum"],"content":"\nInformation can be interpreted as “something” that is encoded in the state of a physical system.\nComputation can be interpreted as “something” that can be carried out on an actual physically realisable device.\nIf we interpret them this way, we can see that the study of these topics might be linked to the underlying physical processes.\n\nSome physical principles related to information and computation\nHere are some noteworthy discoveries in our understanding of how physics constrains our ability to use and manipulate information -\n\nLandauers Principle\nReversible computation\nBennet’s resolution of Maxwell’s Demon\n\nNext: Quantum Information"},"Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Complexity":{"title":"Quantum Complexity","links":["Quantum-Mechanics/Axioms-of-Quantum-Mechanics","Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Parallelism"],"tags":["computation","Quantum","complexity"],"content":"The fact that a Quantum system can perform computations was a fact that was first explicitly pointed out by Paul Benioff and Richard Feynman (independently) in 1982. It was a relevant topic to think about, circuits were becoming smaller and smaller by the passing day. Eventually, these circuits would reach a regime where Quantum effects would become important. This was primarily Benioff’s motivation, but Feynman followed a different motivation (we require a more mathematically precise definition for this).\nDefinitions of information\n\n\n                  \n                  Bit \n                  \n                \n\nThe indivisible unit of Classical information is the bit. It is an “object” that can take either one of two values, 1 or 0.\n\n\nCorresponding to this, we have a Quantum version:\n\n\n                  \n                  Qubit \n                  \n                \n\nIt is the unit of Quantum information. The qubit is a vector in a two dimensional  complex inner product space.\n\n\nIn deference to the bit, we can state the basis of this inner product space using \\{ \\ket{0},\\ket{1}   \\}. Then, we can represent a normalised vector in this space (i.e. a qubit) as:\n\\ket{\\psi} = a \\ket{0} + b \\ket{1}, \\text{  } |a|^{2} + |b|^{2} = 1  \nwhere a, b \\in \\mathbb{C}.\nWe can perform a measurement on this qubit \\ket{\\psi}, which projects it onto the basis vectors \\ket{0} and \\ket{1}. As per Born’s rule (see, Axioms of Quantum Mechanics) the outcome of the measurement operation is not deterministic. the probability that the measurement gives us \\ket{0} is |a|^{2} and the probability that we get \\ket{1} is |b|^{2}.\nExtending this idea, we can express the quantum state of N qubits as a vector in a complex inner product space of dimensions 2^N. We can always choose an orthonormal basis for this space such that the states in which each qubit exists has a definite value, i.e. either \\ket{0} or\\ket{1}. We can label these qubits as:\n\\ket{\\underbrace{001101 \\dots 1010}_{N}} \nWe can expand this in the basis as,\n\\sum_{x=0}^{2^N -1} a_{x} \\ket{x} \nHere, we have associated with each string of binary digits present in a qubit with the corresponding number in decimal base, and then labelled the basis vectors using those decimal digits. Of course, as these are normalized we have:\n\\sum_{x=0}^{2^N -1} |a_{x}|^{2} = 1\nIf we measure all the N qubits by projecting them onto the \\{ \\ket{0}, \\ket{1} \\} basis, the probability of obtaining \\ket{x} is |a_{x}|^{2}.\nDefinition of quantum computation\nNow that the unit of information is defined, we can move on to defining quantum computation. We begin by assembling N qubits in state \\ket{x=0} or \\ket{0}\\ket{0}\\dots \\ket{0} = \\ket{00\\dots 0}. We then apply a unitary transformation U to the N qubits.\n\n\n                  \n                  Note\n                  \n                \n\nThis unitary transformation U can be created out of a direct product of several quantum logic gates that act on a few qubits at a time.\n\n\nAfter we apply U, we measure all the qubits by projecting onto the \\{ \\ket{0}, \\ket{1} \\} basis. this measurement is called the outcome of the quantum computation, and is classical information that can be used.\nSimulation of a quantum computer using a classical computer\nOf course, the probabilistic nature of the measurement operation itself causes thee outcomes of the quantum computation probabilistic - we can run the same computation again to possibly get a different outcome. the quantum algorithm thus generates a probability distribution.\n\n\n                  \n                  Note\n                  \n                \n\nShor’s algorithm for factorisation (by virtue of being a quantum algorithm) is not guaranteed to succeed in finding the prime factors; it just succeeds with a good probability. This is enough because it is very easy to verify whether the factors produced by the algorithm are correct.\n\n\nFrom this description of what a Quantum computer does, it is clear that it can not do anything that a classical computer can’t do. Since we can simulate random numbers, store and rotate vectors in Classical computers, it makes sense that we can simulate a Quantum Computer using one (to an arbitrarily good accuracy). this makes sense, as our notions of what is computable remain the same, whether we use a Classical or a Quantum computer.\n\n\n                  \n                  Space complexity problems in Quantum computation simulation on Classical computers \n                  \n                \n\nSuppose we wish to simulate a modest number of qubits, say, N = 100. To do this, we would essentially need to write down 2^N = 2^{100} \\approx 10^{30} complex numbers - a space requirement too large for all current Classical computers! Not to mention the fact that carrying out a unitary transformation in this complex inner product space is far beyond the capabilities of any Classical computer.\nPut another way, N classical bits can also take on 2^N different values, but each of these values can be represented with ease using just one binary string. In the case of N qubits, each possible value of the qubit requires an enormously ccomplex representation as we have to assign coefficients to 2^N basis vectors in the complex inner prodduct space just to represent it.\n\n\nQuantum mechanics is thus fundamentally computationally “hard” as we must deal with large matrices. There is too much “room” in a Hilbert Space. These observations are what motivated Feynman to assert that a quantum computer would be able to perform certain tasks that would take a classical computer impossibly large timescales to complete.\nTrying to bypass quantum simulation on Classical computers\nBut is such a representation off a qubit during simulatuion by a Classical computer necessary? Can we not use a probabilistic Classical algorithm which generates an outcome that is not uniquely determined by the input, but is rather a probability distribution that coincides with that generated by the Quantum computation.\nEssentially, we are looking to perform a local simulation.\n\n\n                  \n                  Local Quantum simulation \n                  \n                \n\nIn such a simulation,\n\nEach qubit has a definite value (measured/projected) at each time step.\nEach quantum gate can act on the qubit in various possible ways, one of which is selected as determined by a (pseudo-)random number generator.\n\n\n\nSuch a simulation would definitely be much easier to carry out as compared to tracking the unitary evolution of a vector in a large-dimensional space.\nBut Bell’s theorem says precisely that such a simulation will never work: There is no local probabilistic algorithm that can reproduce the conclusions of a quantum computation. While there is no known proof for this, it seems highly likely that simulating a Quantum computer is a very hard problem for any Classical computer.\nWhy is the mathematical description of Quantum information necessarily complex?\nImagine we have a 3N-qubit system (N \\gg 1), divided up into 3 subsystems of N qubits each. Let us label these subsystems as 1, 2, and 3. We take these subsystems, and send them off to different locations.\nAt each location, we will try to carry out measurements on the subsystem sent to that location. Later, we will attempt to piece together the information from all three locations to determine what state the original 3N-qubit system was in. (Let us allow ourselves many such identically prepared 3N-qubit systems so we can carry out several measurements to determine the state - as only one measurement will not do). No collective measurement spanning more than one subsystem is allowed here.\nUnder these conditions, and for a typical 3N-qubit system, these measurements will tell us nothing about the state of the entire system. Nearly all of the information that distinguishes one state of the 3N system from another is stored in the non-local correlations between the measurement outcomes of subsystems 1, 2, and 3. These are the non-local correlations that Bell’s theorem refers to.\nNow, information content can be quantified using a measure of entropy (large entropy means little information content, and vice versa). If we choose a state for the 3N-qubit system randomly, we will find that the entropy of each subsystem is given by:\nS \\approx N - 2^{-(N+1)}\n(result by Don Page)\nThe largest value of entropy here would be N, which represents the case where each subsystem carries nearly no information at all. Thus, for large values of N, we get exponentially smaller information content from separate measurements of subsystems.\nWhen such non-local correlations exist among parts of a system, we say that the parts are “entangled”. This is why a Classical computer will require vast resources to carry out a useful simulation of a quantum computation - we would have to store and compute all of these non-local correlation information.\nNext: Quantum Parallelism"},"Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Errors":{"title":"Errors in Quantum information/ccomputing","links":[],"tags":["Quantum","complexity","errors","computation","information"],"content":""},"Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Information-and-Computation-(Home)":{"title":"Quantum Information and Computation (Home)","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Introduction-to-Quantum-Information-and-Computation"],"tags":["Quantum","QM","infomation","computation","complexity"],"content":"Topics (in logical order)\n\nIntroduction to Quantum Information and Computation\n"},"Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Information":{"title":"Quantum Information","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Physics-of-Information","Uncertainty-Principle","Quantum-Mechanics/Quantum-Information-and-Computation/Efficient-Quantum-Algorithms"],"tags":["information","QM","Quantum"],"content":"From the topics listed in Physics of Information, we can see that information is physical, and that it is indeed useful for us to consider what physics can tell us about information. How does Quantum theory fit in with this “Physics of Information”?\n\n\n                  \n                  Example\n                  \n                \n\nThe clicks of a Geiger Counter when it registers radiation pulses are a truly random (Poisson) process. Quantum theory seems to be able to account for processes like these, but there is no real place for true randomness in Classical dynamics as it is deterministic.\nFurther, in Quantum theory, non-commuting observables can not have well defined values simultaneously (Uncertainty Principle) - If A and B are non-commuting observables, then the measurement of A will necessarily influence the measurement of B. Therefore, the act of acquiring information about a physical system inevitably results in a disturbance in the state of the system.\n\n\nWhy is there such a trade-off between carrying out a measurement on a system and the introduction of disturbances in the state of the system? It is related Quantum randomness - the outcome of an experiment has a random element that we are unable to infer the initial state of the system from the measurement outcome.\nThis leads us to another essential distinction from classical and quantum information - Quantum information can not be copied with perfect fidelity (No-Cloning Principle, Wooters, Zurek, Dieks, 1982). This becomes obvious when we think about it - if we could clone a Quantum system, we could measure two non commuting observables and establish exact values for both simultaneously by carrying out one measurement on the original system and the other on the clone. this would violate the Uncertainty Principle.\nOn the other hand, Classical Information has no such limitation and can be cloned.\nIn the work of John Bell (1964) these differences between Classical and Quantum Information became apparent - he showed that the predictions of Quantum Mechanics can not be reproduced by any local hidden variable theory. Bell showed that quantum information can be (and typically is) stored in non-local correlations between different parts of a physical system - and this has no Classical counterpart.\nNext: Efficient Quantum Algorithms"},"Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Parallelism":{"title":"Quantum Parallelism","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Information","Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Complexity","Quantum-Mechanics/Quantum-Information-and-Computation/New-classifications-of-complexity"],"tags":["computation","information","complexity"],"content":"Feynman’s ideas on the efficiency of quantum algorithms were formulated more concretely by David Deustch in 1985 in terms of something he called “quantum parallelism”.\nAn example of Quantum Parallelism\nLet us have a black box that takes a single bit x as input, and computes some function’s value f(x) (Here, f: \\{ 0,1 \\} \\to \\{ 0,1 \\}). Here’s the catch - the computation process is extremely slow, and takes 24 hours (say).\nOf course, there are only 4 possible functions here (^2C_{2} \\cdot ^2C_{2} = 4). We would like to know what this function is. We would be satisfied to know whether the function is:\n\nConstant, i.e. f(0) = f(1)\nBalanced, i.e. f(0) \\neq f(1)\n\nOf course, we could plug in x = 0 once, and x=1 again after that to map the function completely. But this would take 48 hours! We want to get it done quicker.\nNow, suppose that the black box in question is quantum in nature, and still computes f(x). Now, f may not be invertible (when it is constant, for example) - but the action of the black box computer is invertible and thus unitary. To ensure this, we create a unitary operation given by:\nU_{f} : \\ket{x} \\ket{ y} \\to \\ket{x} \\ket{y \\oplus f(x)}   \nThis operation flips the second qubit if f acting on the first qubit is 1, and does nothing if f acting on the first qubit is 0 . Thus, it is reversible.\nIf we happen to have such a box, we can do the following to find out whether f is constant or balanced:\n\n\n                  \n                  A solution to Deustch&#039;s Problem \n                  \n                \n\nSince the quantum black box can take two qubits (i.e. \\ket{x}\\ket{y}), we prepare the second qubit as a superposition state given by:\n\\ket{y} = \\frac{1}{\\sqrt{ 2 }} (\\ket{0} - \\ket{1} )\nUnder the defined unitary transformation (U_{f}), we would then get:\n\\ket{x} \\left( \\frac{1}{\\sqrt{ 2 }} \\right) (\\ket{0} - \\ket{1} ) \\to \\ket{x} \\left( \\frac{1}{\\sqrt{ 2 }} \\right)(\\ket{f(x)} - \\ket{1 \\oplus f(x)} ) = \\ket{x} \\left( \\frac{1}{\\sqrt{ 2 }} \\right)(-1)^{f(x)} (\\ket{0} - \\ket{1} )  \nf  has thus been isolated in a phase. Further, we set the first qubit to be in the state:\n\\ket{x} = \\frac{1}{\\sqrt{ 2 }} (\\ket{0} + \\ket{1} ) \nPutting in \\ket{x}\\ket{y}, we get the map:\n\\frac{1}{\\sqrt{ 2 }} (\\ket{0} + \\ket{1} ) \\frac{1}{\\sqrt{ 2 }}(\\ket{0} - \\ket{1} ) \\to \\frac{1}{\\sqrt{ 2 }}[(-1)^{f(0)} \\ket{0} + (-1)^{f(1)} \\ket{1} ] \\frac{1}{\\sqrt{ 2 }} (\\ket{0} - \\ket{1} )\nWith this prepared, we carry out a measurement operation on the first output bit of the quantum black box by projecting onto the basis:\n\\ket{\\pm} = \\frac{1}{\\sqrt{ 2 }} (\\ket{0} \\pm \\ket{1} ) \nNote that if f is balanced, we will always get \\ket{-}, and if it is constant we will always get \\ket{+}. thus, we have successfully determined the behaviour of f in just one computation, i.e. 24 hours!\n\n\nWith the solution to this problem, it becomes clear that the quantum computer can do something that classical ones can not - reduce the total number of computation via some sort of “parallel processing”. This is because, unlike the classical computer, the quantum computer can extract “global” information about the function (i.e. information that depends on both f(0) and f(1)) by acting on a superposition state.\nGeneralising further, let us assume a function f that acts on N bits. This function has 2^N possible arguments. To deal with this classically (for N \\gg 1) would be impossible. Assuming a quantum computer with the unitary operation:\nU_{f}: \\ket{x} \\ket{0} \\to \\ket{x} \\ket{f(x)} \n(where  \\ket{x} represents a binary string of length N, and may be labelled by 2^N natural numbers)\nWe can set the input qubit to be the state:\n\\left[  \\frac{1}{\\sqrt{ 2 }} (\\ket{0} + \\ket{1} )  \\right]^N = \\frac{1}{2^{N/2}} \\sum_{x=0}^{2^N - 1} \\ket{x} \ni.e. a linear superposition of all the possible binary strings.\nThe computer will then produce the output:\n\\frac{1}{2^{N/2}} \\sum_{x=0}^{2^N - 1} \\ket{x}\\ket{f(x)}  \nThis output qubit(s) has the global properties of f encoded in it - we can extract it using certain measurement operations. This is a quantum computer that displays massive quantum parallelism - something a classical computer can never carry out.\nAs referenced in Quantum Information and Quantum Complexity, the information of a quantum system is stored in “non-local correlations” between the various physical parts of the system. In the case off these computers, it is stored in the correlations between the input registers and the output registers of the computer - information that is not easy to decipher.\nA look at how measurements can destroy the non-local correlations\nSay we do a measurement operation on the \\ket{x} qubit prepared in the last section - projecting onto the basis set of all possible 2^N binary strings. In this case, we would be collapsing the superposition and essentially preparing the state \\ket{x_{0}}, for some x_{0}.\nPutting this measured qubit into the quantum computer will invariable lead to the output:\n\\ket{x_{0}} \\ket{f(x_{0})} \nWe could measure this by projecting second qubit onto \\{ \\ket{0}, \\ket{1} \\} basis, finding the value of f(x_{0}). But in this process, the intricate correlations among the registers is lost - and we can no longer say anything about f(y_{0}) for some y_{0} \\neq x_{0} by making further measurement operations.\nNext: New classifications of complexity"},"Quantum-Mechanics/Quantum-Information-and-Computation/Reversible-computation":{"title":"Reversible computation","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Landauers-Principle"],"tags":["information","computation","QM","thermodynamics"],"content":"Why computations can be irreversible\nNormally, the logic gates that are used in computation are irreversible. For example, look at the operation of a NAND gate:\n(a,b) \\to \\neg (a \\land b)\nThis takes in two bits, and outputs one bit - and we can not recover an unique input from the output bit. If we refer to Landauers Principle, we can see that since some information is erased in the process, at least W = k T \\ln 2 must be supplied to operate this gate.\nBennet’s method\nThus, if we have a finite amount of energy at our disposal, we can only carry out a finite number of computations.\nIn 1973, Charles Bennet found that any computation can be performed using only reversible steps - thus in principle we can compute without any power expenditure or dissipation.\nFor example, we can construct a reversible version of the NAND Gate (Toffoli Gate):\n(a,b,c) \\to (a,b,c \\oplus a \\land b)\nThis is a reversible 3-bit gate, which operates by flipping the third bit (c) if both the two first bits (a,b) take the value 1, and does nothing else otherwise. Here \\oplus is acting simply as a binary addition (without a carry, i.e. it adds and then selects the least bit). If c=1, then the third output bit from this gate is the NAND of a and b. This gate can, in principle, be carried out without any dissipation as for all output triplet we can find a unique input triplet.\nBut aren’t we generating a lot of junk in this computation? Technically, (a.b) bits are not useful in the result of the computation. Only c is required. So, we might want to delete this “junk” in the process of computation - which means that we are just postponing the energy cost of the computation.\nBennet countered this by proposing the following mode of action for the reversible computer - The computer carries out all the reversible computations it is required to do, prints the complete output (Note, printing is itself logically reversible), then reverses the computational steps to return to its initial configuration. This removes the junk without any energy cost!\nIn practice, most modern computers require energy dissipation that is orders of magnitude greater than the energy dissipation predicted by the Landauer Principle - so Bennet’s reversible computation method is not really important for them. But as we shrink the components of the computer, we might require Bennet’s method to beat the Landauer Limit - as otherwise the components can be damaged by the heat generated."},"Quantum-Mechanics/Quantum-Mechanics-(Home)":{"title":"Quantum Mechanics (Home)","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Information-and-Computation-(Home)","Quantum-Mechanics/Non-Relativistic-Quantum-Mechanics/Non-Relativistic-Quantum-Mechanics-(Home)"],"tags":["Quantum","Home"],"content":"Topics\n\nQuantum Information and Computation (Home)\nNon Relativistic Quantum Mechanics (Home)\n"},"Quantum-Mechanics/The-Schrodinger-Equation":{"title":"The Schrodinger Equation","links":["Quantum-Mechanics/Non-Relativistic-Quantum-Mechanics/SE-preserves-normalization-(Proof)","Quantum-Mechanics/Non-Relativistic-Quantum-Mechanics/Conservation-of-probability-current-associated-with-wavefunction-(Proof)","Quantum-Mechanics/Non-Relativistic-Quantum-Mechanics/Stationary-Solutions"],"tags":["Quantum","QM","Schrodinger"],"content":"In Classical Mechanics, we are used to describing the motion of a particle using a time dependent 3D vector - \\vec{x}(t) as the dynamical variable.\nIn Quantum Theory and related wave mechanics, the dynamical variable is instead a wavefunction.\n\n\n                  \n                  Naive definition of a wavefunction \n                  \n                \n\nA wavefunction is generally a complex valued function whose value depends upon both time and space.\nWhen all 3 dimensions of space are relevant, we may express such a wavefunction by:\n\\Psi (\\vec{x},t) \\in \\mathbb{C}\n\n\nIf there is just one relevant space dimenson, we may write:\n\\Psi (x,t) \\in \\mathbb{C}\nA valid wavefunction in Quantum Mechanics is characterized by the fact that it is solution to the Schrodinger Equation. We may write the Schrodinger equation as:\ni \\hbar \\frac{ \\partial \\Psi }{ \\partial t } (x, t) = \\left( - \\frac{\\hbar^{2}}{2m} \\frac{ \\partial^{2}  }{ \\partial x^{2} } + V(x,t) \\right) \\Psi (x,t) \\text{ , For 1 dimension}\ni \\hbar \\frac{ \\partial \\Psi }{ \\partial t } (\\vec{x},t) = \\left( - \\frac{\\hbar^{2}}{2m}\\nabla^{2} + V(\\vec{x},t) \\right) \\Psi (\\vec{x},t) \\text{ , For 3 dimensions}\nThe equations describe a particle (non-relativistic) of mass m moving (along the x-axis, for the 1D case) while acted upon by the potential V(\\vec{x},t) \\in \\mathbb{R}.\nNote that the wavefunction is necessarily complex! If it was real, then the right-hand-side of the SE would be entirely real while the left-hand-side of the SE would be completely imaginary - something that can not happen.\nWe make the following remarks:\n\nThe Schrodinger equation is a First-oder differential equation in time.\n\nThis means that if we specify a wavefunction \\Psi (\\vec{x},t_{0}), then the wavefunction is determined \\forall t.\n\n\nThe Schrodinger equation is a linear equation in \\Psi, i.e. if \\Psi_{1} and \\Psi_{2} are solutions to the SE, then \\Psi_{1} + \\Psi_{2} is also a valid solution of the SE.\n\nProbability (Born interpretation)\nWe can define a probability density for a valid wavefunction, as follows:\nP (x,t) \\equiv \\Psi^{*}(x,t) \\Psi(x,t) = \\lvert \\Psi(x,t) \\rvert^{2} \nobviously, the definition satissfies the requirement that the PDF be positive definite. We may also interpret this PDF in the following way:\n\n\n                  \n                  Interpretation of the PDF of a wavefunction \n                  \n                \n\nP(x,t) dx is the Probability to find the particle represented by the wavefunction in the interval [x, x+ dx] at some time t.\n\n\nOf course, if we interpret the PDF this way, it must be normalizable to unity as required by the Axioms of Probability. This is given by:\n\\int_{- \\infty}^{\\infty} \\lvert \\Psi(x,t) \\rvert^{2}  \\, dx = 1 , \\forall t \nIs normalization of the wavefunction preserved under time-evolution of the wavefunction?\nSuppose that we have a wavefunction \\Psi that has been normalized at some time t_{0}:\n\\int_{- \\infty}^{\\infty} \\lvert \\Psi(x,t_{0}) \\rvert^{2}   \\, dx = 1 \nWe have previously claimed that if a valid wavefunction is specified for some time t_{0}, it is specfied \\forall t. In addition to this, if the interpretation of the probability density defined is to hold, we have to verify that the Schroddinger equation guarantees that the wavefunction remains normalized at all times.\n\nSee: SE preserves normalization (Proof)\n\nProbability current\nIt is interesting to note that a form that shows up during the proof, namely:\nJ (x,t) = \\frac{\\hbar}{m} \\mathrm{Im}\\left( \\Psi^{*} \\frac{ \\partial \\Psi }{ \\partial x }  \\right)\nis defined as the Probability current associated with the wavefunction. It is useful to characterise the flow of probability. As it is a current of a conserved quantity (Probability), it clearly has a conservation equation:\n\\vec{\\nabla} \\cdot \\vec{J} + \\frac{ \\partial \\rho }{ \\partial t } = 0\n\nSee: Conservation of probability current associated with wavefunction (Proof)\n\nThis quantity is often very useful. For example, let us define P_{ab}(t) as the probability of finding the particle represented by \\Psi(x,t) in the interval [a,b]:\nP_{ab}(t) = \\int_{a}^{b} \\lvert \\Psi(x,t) \\rvert ^{2} \\, d = \\int_{a}^{b} \\rho(x,t) \\, dx  \nUsing the definition of the probability current here, w can easily show that:\n\\frac{d P_{ab}(t)}{dt} = J(a,t) - J(b,t) \nwhich is an equation hich looks quite like a master equation, with terms for inflow and outflow of probabilities on the right-hand-side.\nPhysically equivalent wavefunctions\nSometimes, it is easier to deal with wavefunctions that are not normalized. In this spirit, we may defined that two wavefunctions \\Psi_{1} and \\Psi_{2} are physically equivalent if they differ by multiplication with some complex number. We normally write this as:\n\\Psi_{1} \\sim \\Psi_{2} \\leftrightarrow \\Psi_{1}(x,t) = \\alpha \\Psi_{2}(x,t), \\alpha \\in \\mathbb{C}\nNote: If \\Psi_{1} and \\Psi_{2} are both normalized, then they must differ by multiplication with some overall constant phase factor, i.e. e^{ i \\theta }, \\theta \\in \\mathbb{R}.\nNext: Stationary Solutions"},"Statistical-Mechanics/Statistical-Mechanics-(Home)":{"title":"Statistical Mechanics (Home)","links":["Kinetic-theory-of-gases","Classical-statistical-mechanics","Interacting-particles","Quantum-statistical-mechanics","Ideal-quantum-gases"],"tags":["statistical-mechanics","statistics"],"content":"Topics in Statistical mechanics of particles (in logical order)\n\nThermodynamics (Prerequisite)\nProbability Theory (Prerequisite)\nKinetic theory of gases\nClassical statistical mechanics\nInteracting particles\nQuantum statistical mechanics\nIdeal quantum gases\n"},"index":{"title":"Welcome to Casio Notes!","links":[],"tags":[],"content":"Hi! Welcome to my collection of academic notes, mostly revolving around topics in Physics, Mathematics, and some Computer Science/Electronics. I try to keep it modular and wiki-like.\nAn effort has been made to maintain a sort of order in the topics covered - this is mainly in the order of difficulty and/or prerequisites. An excellent self-study guide for theoretical physics can be found on Gerard’t Hooft’s Personal website (here).\nIf you find any errors or dead reference links, please feel free to either comment or get in touch over email (here).\nHope this is of some use!"}}