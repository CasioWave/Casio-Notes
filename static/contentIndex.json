{"Quantum-Mechanics/Axioms-of-Quantum-Mechanics":{"slug":"Quantum-Mechanics/Axioms-of-Quantum-Mechanics","title":"Axioms of Quantum Mechanics","links":[],"tags":["Quantum","QM","Axioms"],"content":"The following are the axioms of Quantum Mechanics -\n\n\nThe properties of quantum systems are completely defined by the specification of its state vector, denoted generally by \\ket{\\psi}. The state vector is an element of a complex Hilbert Space \\mathbb{H}, called the space of states.\n\n\nWith every physical property \\mathcal{A}, there exists a corresponding linear, Hermitian operator A called an observable, which acts in the Hilbert space \\mathbb{H}.\n\nThe eigenvalues of these Hermitian operators are values of the physical properties.\n\n\n\n(Born Rule) If \\ket{\\psi} is the vector in \\mathbb{H} representing the state of the system, and \\ket{\\phi} represents a particular physical state of the system, we can define a probability P(\\ket{\\psi},\\ket{\\phi}) for finding \\ket{\\psi} in the state \\ket{\\phi}. This is given by,\n\n\nP(\\ket{\\psi},\\ket{\\phi}  ) = |\\braket{ \\psi | \\phi } |^{2}\nWhere \\braket{ \\cdot | \\cdot } denotes the inner product defined on the Hilbert Space.\n\n(Wave function collapse) If A is an observable with the eigenvalues listed in the set \\{ a_{n} \\} and the eigenvectors listed in the set \\{ \\ket{n} \\}, and we have a system in a given state \\ket{\\psi}, the probability of obtaining a_{n} as the “outcome” of the measurement of \\mathcal{A} (the physical property corresponding to the observable), i.e. on the action of A on \\ket{\\psi} is given by,\n\nP(a_{n}) = |\\braket{ n | \\psi } |^{2}\nAfter such a measurement operation is done, the system is left in the state \\ket{n}, i.e the wave function \\ket{\\psi} “collapses” to that state.\n\nThe time-evolution of a closed system as described in Quantum Mechanics is unitary, i.e. reversible. The evolution is given by the time-dependent Schrodinger equation -\n\ni \\hbar \\frac{\\partial \\ket{\\psi}}{\\partial t} = H \\ket{\\psi} \nWhere H is the Hamiltonian of the system, \\hbar is the reduced Planck constant, and i is \\sqrt{ -1 }.\nReferences\n\nQuantum Theory of Radiation Interaction - MIT OCW, Fall 2012\n"},"Quantum-Mechanics/Quantum-Information-and-Computation/Bennet's-resolution-of-Maxwell's-Demon":{"slug":"Quantum-Mechanics/Quantum-Information-and-Computation/Bennet's-resolution-of-Maxwell's-Demon","title":"Bennet's resolution of Maxwell's Demon","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Landauers-Principle","Quantum-Mechanics/Quantum-Information-and-Computation/Reversible-computation","Maxwell's-Demon","2nd-Law-of-Thermodynamics"],"tags":["infomation","thermodynamics","computation"],"content":"From the insights obtained from both Landauers Principle and Reversible computation (Bennet’s method), Bennet was able to reconcile Maxwell’s Demon (the actual thought experiment is not described on this page) with the 2nd Law of Thermodynamics.\nLooking at the demon using information theory\nIf the demon is to discern between a “fast” and a “slow” particle and open the shutter between the partitions based on this information - the demon must collect and store information about the particles of gas. It must also compute using this information to know when to open and close the gate. If the demon has a finite memory, the demon can not continue to cool the gas indefinitely - at some point it must erase its memory to carry on, which has an energy cost. So work is done to transfer heat from a body at a lower temperature to a body at a higher temperature, and the 2nd Law of Thermodynamics is not violated!\n\n\n                  \n                  Note\n                  \n                \n\nIf we want to account for the energy expenditure before the demon erases its memory, we must associate some entropy with the information recorded by the demon.\nSzilard, and some history\nThis particular resolution to the Maxwell’s Demon problem was largely anticipated by Leo Szilard in 1929 - he invented the concept of a bit of information (the term “bit” was coined later by Tukey) and he associated the entropy \\Delta S = k \\ln 2 with the acquisition of a bit of information. Note that Szilard did not seem to have arrived at Landauer’s Principle - that it was the erasure of the bit that carries the energy cost."},"Quantum-Mechanics/Quantum-Information-and-Computation/Efficient-Quantum-Algorithms":{"slug":"Quantum-Mechanics/Quantum-Information-and-Computation/Efficient-Quantum-Algorithms","title":"Efficient Quantum Algorithms","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Information","Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Complexity"],"tags":["QM","computation","Quantum"],"content":"From what we have seen in Quantum Information, it is clear that Quantum Theory will have profound effects on our understanding of computation.\nIn April 1994, Peter Shor demostrated that, in principle, a Quantum computer can factor a large number “efficiently”.\n\n\n                  \n                  Note\n                  \n                \n\nFactoring (i.e. findding the prime factors) of a large composite number is an example of an intractable problem. It has these properties:\n\nThe solution is very “easy” to verify once found.\nThe solution is “hard” to find\n\nIf p and q are large prime numbers, the product n = pq is something that can be computed very quickly (No. of required operations is roughly \\log_{2}p \\cdot \\log_{2}q). But, if we are given just n, it is “hard” to find p and q.\nIt has been conjectured (but not proved) that the number of operations required to find the factors is superpolynomial in \\log n, i.e. as n increases the number of operations increases faster than any power of \\log n.\nThe best known algorithm for factoring, the “Number Field Sieve” requires roughly \\exp\\left( c(\\ln n)^\\left( \\frac{1}{3} \\right) (\\ln (\\ln n))^\\left( \\frac{2}{3} \\right) \\right), where c \\approx 1.9.\nUsing this algorithm, we can estimate that factoring a 400 digit number would take about 10^{10} years - the age of the universe (assuming a computer that takes 1 month to factor a 130 digit number)\n\n\nIn the context of Complexity theory, an “intractable” problem essentially means a problem that can not solved in a time bounded by a polynomial in the size of the input (in this case, that is \\log n). This is practically important in topics like cryptography (e.g. RSA cryptography).\nShor’s Result\nShor showed that a Quantum computer can factor in polynomial time! More precisely, in time:\nO[(\\ln n)^3]\nUsing the same computer, this Quantum Algorithm can factor a 400 digit number in just 3 years. the harder the problem, the greater the advantage enjoyed by the Quantum computer.\nNext: Quantum Complexity"},"Quantum-Mechanics/Quantum-Information-and-Computation/Introduction-to-Quantum-Information-and-Computation":{"slug":"Quantum-Mechanics/Quantum-Information-and-Computation/Introduction-to-Quantum-Information-and-Computation","title":"Introduction to Quantum Information and Computation","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Physics-of-Information","Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Information","Quantum-Mechanics/Quantum-Information-and-Computation/Efficient-Quantum-Algorithms","Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Complexity","Quantum-Parallelism","New-classifications-of-complexity","Quantum-Errors","Quantum-Error-Correcting-Codes","Quantum-Hardware"],"tags":["Quantum","computation","information"],"content":"Topics (in order)\n\nPhysics of Information\nQuantum Information\nEfficient Quantum Algorithms\nQuantum Complexity\nQuantum Parallelism\nNew classifications of complexity\nQuantum Errors\nQuantum Error-Correcting Codes\nQuantum Hardware\n\nSummary\nReferences\n\nMost of these notes at the moment (March 2025) are drawn from John Preskill’s Lecture Notes on Quantum Information and Computation, Physics 229 at Caltech. A pdf of the notes can be found here\n"},"Quantum-Mechanics/Quantum-Information-and-Computation/Landauers-Principle":{"slug":"Quantum-Mechanics/Quantum-Information-and-Computation/Landauers-Principle","title":"Landauer's Principle","links":[],"tags":["information","thermodynamics","QM"],"content":"In 1961 Rolf Landauer pointed out that the erasure of information is necessarily a dissipative process. He saw that erasure of information always involves the compression of phase space, and thus it is irreversible.\nExample: Suppose we have a box with a partition in the middle, separating the box into “Left” and “Right” sections. We can store a bit of information in this box by keeping one molecule of gas in either the “Right” or the “Left” section. To erase the information here, we can choose to bring this molecule to the “Left” of the box, regardless of where it was originally (and then forget where we brought it from; that is essentially the “erasure”). We can do this by - 1. Removing the partition. This causes this “one molecule gas” to expand into the entire box, 2. Putting in a movable partition at the right wall of the box, and then moving it to “compress” the “one molecule gas” into the “Left” section. Now, in doing so, we do some work! If the process is isothermal (at some temperature T), then the work done on the box-gas system is given exactly by W = T \\Delta S = k T \\ln 2.\n\n“If I am to erase information, someone will have to pay the power bill” - John Preskill.\n"},"Quantum-Mechanics/Quantum-Information-and-Computation/Physics-of-Information":{"slug":"Quantum-Mechanics/Quantum-Information-and-Computation/Physics-of-Information","title":"Physics of Information","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Landauers-Principle","Quantum-Mechanics/Quantum-Information-and-Computation/Reversible-computation","Quantum-Mechanics/Quantum-Information-and-Computation/Bennet's-resolution-of-Maxwell's-Demon","Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Information"],"tags":["infomation","QM","Quantum"],"content":"\nInformation can be interpreted as “something” that is encoded in the state of a physical system.\nComputation can be interpreted as “something” that can be carried out on an actual physically realisable device.\nIf we interpret them this way, we can see that the study of these topics might be linked to the underlying physical processes.\n\nSome physical principles related to information and computation\nHere are some noteworthy discoveries in our understanding of how physics constrains our ability to use and manipulate information -\n\nLandauers Principle\nReversible computation\nBennet’s resolution of Maxwell’s Demon\n\nNext: Quantum Information"},"Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Complexity":{"slug":"Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Complexity","title":"Quantum Complexity","links":["Quantum-Mechanics/Axioms-of-Quantum-Mechanics"],"tags":["computation","Quantum","complexity"],"content":"The fact that a Quantum system can perform computations was a fact that was first explicitly pointed out by Paul Benioff and Richard Feynman (independently) in 1982. It was a relevant topic to think about, circuits were becoming smaller and smaller by the passing day. Eventually, these circuits would reach a regime where Quantum effects would become important. This was primarily Benioff’s motivation, but Feynman followed a different motivation (we require a more mathematically precise definition for this).\n\n\n                  \n                  Bit \n                  \n                \n\nThe indivisible unit of Classical information is the bit. It is an “object” that can take either one of two values, 1 or 0.\n\n\nCorresponding to this, we have a Quantum version:\n\n\n                  \n                  Qubit \n                  \n                \n\nIt is the unit of Quantum information. The qubit is a vector in a two dimensional  complex inner product space.\n\n\nIn deference to the bit, we can state the basis of this inner product space using \\{ \\ket{0},\\ket{1}   \\}. Then, we can represent a normalized vector in this space (i.e. a qubit) as:\n\\ket{\\psi} = a \\ket{0} + b \\ket{1}, \\text{  } |a|^{2} + |b|^{2} = 1  \nwhere a, b \\in \\mathbb{C}.\nWe can perform a measurement on this qubit \\ket{\\psi}, which projects it onto the basis vectors \\ket{0} and \\ket{1}. As per Born’s rule (see, Axioms of Quantum Mechanics) the outcome of the measurement operation is not deterministic. the probability that the measurement gives us \\ket{0} is |a|^{2} and the probability that we get \\ket{1} is |b|^{2}.\nExtending this idea, we can express the quantum state of N qubits as a vector in a complex inner product space of dimensions 2^N. We can always choose an ortonormal basis for this space such that the states in which each qubit exists has a definite value, i.e. either \\ket{0} or\\ket{1}. We can label these qubits as:\n\\ket{\\underbrace{001101 \\dots 1010}_{N}} \nWe can expand this in the basis as,\n\\sum_{x=0}^{2^N -1} a_{x} \\ket{x} \nHere, we have associated with each string of binary digits present in a qubit with the corresponding number in decimal base, and then labelled the basis vectors using those decimal digits. Of course, as these are normalized we have:\n\\sum_{x=0}^{2^N -1} |a_{x}|^{2} = 1\nIf we measure all the N qubits by projecting them onto the \\{ \\ket{0}, \\ket{1} \\} basis, the probability of obtaining \\ket{x} is |a_{x}|^{2}.\nNow that the unit of information is defined, we can move on to defining quantum computation. We begin by assembling N qubits in state \\ket{x=0} or \\ket{0}\\ket{0}\\dots \\ket{0} = \\ket{00\\dots 0}. We then apply a unitary transformation U to the N qubits.\n\n\n                  \n                  Note\n                  \n                \n\nThis unitary transformation U can be created out of a direct product of several quantum logic gates that act on a few qubits at a time.\n\n\nAfter we apply U, we measure all the qubits by projecting onto the \\{ \\ket{0}, \\ket{1} \\} basis. this measurement is called the outcome of the quantum computation, and is classical information that can be used.\nOf course, the prrobabilistic nature of the measurement operation itself causes thee outcomes of the quantum computation proabilistic - we can run the same computation again to possibly get a different outcome. the quantum algorithm thus generates a probability distribution.\n\n\n                  \n                  Note\n                  \n                \n\nShor’s algorithm for factorisation (by virtue of being a quantum algorithm) is not guaranteed to succeed in finding the prime factors; it just succeeds with a good probability. This is enough because it is very easy to verify whether the factors produced by the algorithm are correct.\n\n"},"Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Information":{"slug":"Quantum-Mechanics/Quantum-Information-and-Computation/Quantum-Information","title":"Quantum Information","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Physics-of-Information","Uncertainty-Principle","Quantum-Mechanics/Quantum-Information-and-Computation/Efficient-Quantum-Algorithms"],"tags":["information","QM","Quantum"],"content":"From the topics listed in Physics of Information, we can see that information is physical, and that it is indeed useful for us to consider what physics can tell us about information. How does Quantum theory fit in with this “Physics of Information”?\n\n\n                  \n                  Example\n                  \n                \n\nThe clicks of a Geiger Counter when it registers radiation pulses are a truly random (Poisson) process. Quantum theory seems to be able to account for processes like these, but there is no real place for true randomness in Classical dynamics as it is deterministic.\nFurther, in Quantum theory, non-commuting observables can not have well defined values simultaneously (Uncertainty Principle) - If A and B are non-commuting observables, then the measurement of A will necessarily influence the measurement of B. Therefore, the act of acquiring information about a physical system inevitably results in a disturbance in the state of the system.\n\n\nWhy is there such a tradeoff between carrying out a measurement on a system and the introduction of disturbances in the state of the syste? It is related Quantum randomness - the outcome of an experiment has a random element that we are unable to infer the initial state of the system from the measurement outcome.\nThis leads us to another essential distinction from classical and quantum information - Quantum information can not be copied with perfect fidelity (No-Cloning Principle, Wooters, Zurek, Dieks, 1982). This becomes obvious when we think about it - if we couldd clone a Quantum system, we could measure two non commuting observables and establish exact values for both simultaneously by carrying out one measurement on the original system and the other on the clone. this would violate the Uncertainty Principle.\nOn the other hand, Classical Information has no such limitation and can be cloned.\nIn the work of John Bell (1964) these differences between Classical and Quantum Information became apparent - he showed that the predictions of Quantum Mechanics can not be reproduced by any local hidden variable theory. Bell showed that quantum information can be (and typically is) stored in non-local correlations between different parts of a physical system - and this has no Classical counterpart.\nNext: Efficient Quantum Algorithms"},"Quantum-Mechanics/Quantum-Information-and-Computation/Reversible-computation":{"slug":"Quantum-Mechanics/Quantum-Information-and-Computation/Reversible-computation","title":"Reversible computation","links":["Quantum-Mechanics/Quantum-Information-and-Computation/Landauers-Principle"],"tags":["information","computation","QM","thermodynamics"],"content":"Why computations can be irreversible\nNormally, the logic gates that are used in computation are irreversible. For example, look at the operation of a NAND gate:\n(a,b) \\to \\neg (a \\land b)\nThis takes in two bits, and outputs one bit - and we can not recover an unique input from the output bit. If we refer to Landauers Principle, we can see that since some information is erased in the process, at least W = k T \\ln 2 must be supplied to operate this gate.\nBennet’s method\nThus, if we have a finite amount of energy at our disposal, we can only carry out a finite number of computations.\nIn 1973, Charles Bennet found that any computation can be performed using only reversible steps - thus in principle we can compute without any power expenditure or dissipation.\nFor example, we can construct a reversible version of the NAND Gate (Toffoli Gate):\n(a,b,c) \\to (a,b,c \\oplus a \\land b)\nThis is a reversible 3-bit gate, which operates by flipping the third bit (c) if both the two first bits (a,b) take the value 1, and does nothing else otherwise. Here \\oplus is acting simply as a binary addition (without a carry, i.e. it adds and then selects the least bit). If c=1, then the third output bit from this gate is the NAND of a and b. This gate can, in principle, be carried out without any dissipation as for all output triplet we can find a unique input triplet.\nBut aren’t we generating a lot of junk in this computation? Technically, (a.b) bits are not useful in the result of the computation. Only c is required. So, we might want to delete this “junk” in the process of computation - which means that we are just postponing the energy cost of the computation.\nBennet countered this by proposing the following mode of action for the reversible computer - The computer carries out all the reversible computations it is required to do, prints the complete output (Note, printing is itself logically reversible), then reverses the computational steps to return to its initial configuration. This removes the junk without any energy cost!\nIn practice, most modern computers require energy dissipation that is orders of magnitude greater than the energy dissipation predicted by the Landauer Principle - so Bennet’s reversible computation method is not really important for them. But as we shrink the components of the computer, we might require Bennet’s method to beat the Landauer Limit - as otherwise the components can be damaged by the heat generated."},"index":{"slug":"index","title":"Welcome to Casio Notes!","links":[],"tags":[],"content":"Hi! Welcome to my collection of academic notes, mostly revolving around topics in Physics, Mathematics, and some Computer Science/Electronics. I try to keep it modular and wiki-like.\nIf you find any errors or dead reference links, please feel free to either comment or get in touch over email (here).\nHope this is of some use!"},"preamble.sty":{"slug":"preamble.sty","title":"preamble.sty","links":[],"tags":[],"content":"\\usepackage{physics}\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\C}{\\mathbb{C}}"}}